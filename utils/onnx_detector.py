"""
onnx_detector.py - ONNX ê¸°ë°˜ YOLO ê°ì²´ íƒì§€ ëª¨ë“ˆ

[ì£¼ìš” ê¸°ëŠ¥]
- ONNX Runtimeì„ ì‚¬ìš©í•œ YOLO ëª¨ë¸ ì¶”ë¡ 
- FP16 + 640x640 í•´ìƒë„ ì§€ì›
- ìˆ˜ë™ NMS (Non-Maximum Suppression) êµ¬í˜„
- PIL Image ì§ì ‘ ì…ë ¥ ì§€ì› (íŒŒì¼ ê²½ë¡œ ë¶ˆí•„ìš”)

[ì‚¬ìš©ë²•]
    from utils.onnx_detector import OnnxYoloDetector
    
    # ë‹¨ì¼ ëª¨ë¸
    detector = OnnxYoloDetector("models/cannon.onnx")
    results = detector.detect(pil_image, conf_threshold=0.25)
    
    # ë“€ì–¼ ëª¨ë¸ íƒì§€
    results, meta = detect_all_objects_dual_onnx(
        img_pil, detector_cannon, detector_integrated, ...
    )
"""

import numpy as np
from PIL import Image
from typing import List, Dict, Tuple, Optional, Union
import time

# ONNX Runtime import (GPU ìš°ì„ , CPU í´ë°±)
try:
    import onnxruntime as ort
    ONNX_AVAILABLE = True
except ImportError:
    ONNX_AVAILABLE = False
    print("[ONNX_DETECTOR] âš ï¸ onnxruntime not installed. pip install onnxruntime-gpu")


class OnnxYoloDetector:
    """
    ONNX ê¸°ë°˜ YOLO ê°ì²´ íƒì§€ê¸°
    
    Args:
        model_path: ONNX ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        input_size: ëª¨ë¸ ì…ë ¥ í¬ê¸° (width, height), ê¸°ë³¸ê°’ (640, 640)
        use_gpu: GPU ì‚¬ìš© ì—¬ë¶€, ê¸°ë³¸ê°’ True (ì‚¬ìš© ê°€ëŠ¥ ì‹œ)
        fp16: FP16 ëª¨ë“œ ì—¬ë¶€, ê¸°ë³¸ê°’ False
    
    Example:
        detector = OnnxYoloDetector("models/best.onnx")
        detections = detector.detect(pil_image, conf_threshold=0.25)
    """
    
    def __init__(
        self, 
        model_path: str, 
        input_size: Tuple[int, int] = (640, 640),
        use_gpu: bool = True,
        fp16: bool = False
    ):
        if not ONNX_AVAILABLE:
            raise RuntimeError("onnxruntime is not installed")
        
        self.model_path = model_path
        self.input_size = input_size  # (width, height)
        self.fp16 = fp16
        
        # ONNX Runtime ì„¸ì…˜ ìƒì„±
        self.session = self._create_session(model_path, use_gpu)
        
        # ì…ë ¥/ì¶œë ¥ ì •ë³´ ì¶”ì¶œ
        self.input_name = self.session.get_inputs()[0].name
        self.output_names = [o.name for o in self.session.get_outputs()]
        
        # ì…ë ¥ shape í™•ì¸ (NCHW í˜•ì‹)
        input_shape = self.session.get_inputs()[0].shape
        if input_shape[2] is not None and input_shape[3] is not None:
            self.input_size = (input_shape[3], input_shape[2])  # (W, H)
        
        print(f"[ONNX_DETECTOR] âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
        print(f"  - ì…ë ¥ í¬ê¸°: {self.input_size}")
        print(f"  - FP16 ëª¨ë“œ: {self.fp16}")
        print(f"  - ì¶œë ¥ ë ˆì´ì–´: {self.output_names}")
    
    def _create_session(self, model_path: str, use_gpu: bool) -> 'ort.InferenceSession':
        """ONNX Runtime ì„¸ì…˜ ìƒì„±"""
        providers = []
        
        if use_gpu:
            # CUDA ì‚¬ìš© ê°€ëŠ¥ ì‹œ GPU ìš°ì„ 
            if 'CUDAExecutionProvider' in ort.get_available_providers():
                providers.append('CUDAExecutionProvider')
                print("[ONNX_DETECTOR] ğŸš€ CUDA GPU ê°€ì† í™œì„±í™”")
            elif 'DmlExecutionProvider' in ort.get_available_providers():
                providers.append('DmlExecutionProvider')
                print("[ONNX_DETECTOR] ğŸš€ DirectML GPU ê°€ì† í™œì„±í™”")
        
        # CPU í´ë°±
        providers.append('CPUExecutionProvider')
        
        # GPU ê°€ì†ì´ ì—†ìœ¼ë©´ CPU ì‚¬ìš© ë©”ì‹œì§€ ì¶œë ¥
        if len(providers) == 1:
            print("[ONNX_DETECTOR] ğŸ¢ CPU ëª¨ë“œë¡œ ì‹¤í–‰ (GPU ê°€ì† ì—†ìŒ)")
            
        sess_options = ort.SessionOptions()
        sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
        
        return ort.InferenceSession(model_path, sess_options, providers=providers)
    
    def preprocess(self, img_pil: Image.Image) -> Tuple[np.ndarray, Tuple[float, float], Tuple[int, int]]:
        """
        ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (PIL Image -> ONNX ì…ë ¥ í…ì„œ)
        
        Args:
            img_pil: PIL Image ê°ì²´
        
        Returns:
            Tuple: (input_tensor, scale_factors, original_size)
                - input_tensor: NCHW í˜•ì‹ì˜ float32 í…ì„œ
                - scale_factors: (scale_x, scale_y) ìŠ¤ì¼€ì¼ ë¹„ìœ¨
                - original_size: (ì›ë³¸_width, ì›ë³¸_height)
        """
        original_size = img_pil.size  # (width, height)
        target_w, target_h = self.input_size
        
        # ë¦¬ì‚¬ì´ì¦ˆ (ë¹„ìœ¨ ìœ ì§€í•˜ë©° letterbox)
        img_resized, scale, pad = self._letterbox(img_pil, (target_w, target_h))
        
        # PIL -> numpy (RGB)
        img_np = np.array(img_resized, dtype=np.float32)
        
        # ì •ê·œí™” [0, 255] -> [0, 1]
        img_np = img_np / 255.0
        
        # HWC -> CHW
        img_np = img_np.transpose(2, 0, 1)
        
        # ë°°ì¹˜ ì°¨ì› ì¶”ê°€ (NCHW)
        img_np = np.expand_dims(img_np, axis=0)
        img_np = img_np.astype(np.float32)
        
        # ìŠ¤ì¼€ì¼ íŒ©í„° ê³„ì‚° (ë³µì›ìš©)
        scale_factors = (scale, pad)
        
        return img_np, scale_factors, original_size
    
    def _letterbox(
        self, 
        img_pil: Image.Image, 
        target_size: Tuple[int, int],
        color: Tuple[int, int, int] = (114, 114, 114)
    ) -> Tuple[Image.Image, float, Tuple[int, int]]:
        """
        Letterbox ë¦¬ì‚¬ì´ì§• (ë¹„ìœ¨ ìœ ì§€ + íŒ¨ë”©)
        
        Args:
            img_pil: ì›ë³¸ PIL Image
            target_size: ëª©í‘œ í¬ê¸° (width, height)
            color: íŒ¨ë”© ìƒ‰ìƒ (R, G, B)
        
        Returns:
            Tuple: (ë¦¬ì‚¬ì´ì¦ˆëœ ì´ë¯¸ì§€, ìŠ¤ì¼€ì¼, íŒ¨ë”©)
        """
        orig_w, orig_h = img_pil.size
        target_w, target_h = target_size
        
        # ìŠ¤ì¼€ì¼ ê³„ì‚° (ë¹„ìœ¨ ìœ ì§€)
        scale = min(target_w / orig_w, target_h / orig_h)
        new_w = int(orig_w * scale)
        new_h = int(orig_h * scale)
        
        # ë¦¬ì‚¬ì´ì¦ˆ
        img_resized = img_pil.resize((new_w, new_h), Image.BILINEAR)
        
        # íŒ¨ë”© ê³„ì‚°
        pad_w = (target_w - new_w) // 2
        pad_h = (target_h - new_h) // 2
        
        # ìƒˆ ìº”ë²„ìŠ¤ì— ë°°ì¹˜
        new_img = Image.new("RGB", target_size, color)
        new_img.paste(img_resized, (pad_w, pad_h))
        
        return new_img, scale, (pad_w, pad_h)
    
    def postprocess(
        self, 
        outputs: List[np.ndarray], 
        scale_factors: Tuple[float, Tuple[int, int]],
        original_size: Tuple[int, int],
        conf_threshold: float = 0.25,
        iou_threshold: float = 0.45
    ) -> List[Dict]:
        """
        ëª¨ë¸ ì¶œë ¥ í›„ì²˜ë¦¬ (NMS í¬í•¨)
        
        Args:
            outputs: ONNX ëª¨ë¸ ì¶œë ¥
            scale_factors: (scale, (pad_w, pad_h))
            original_size: (ì›ë³¸_width, ì›ë³¸_height)
            conf_threshold: ì‹ ë¢°ë„ ì„ê³„ê°’
            iou_threshold: NMS IoU ì„ê³„ê°’
        
        Returns:
            List[Dict]: íƒì§€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
                ê° ë”•ì…”ë„ˆë¦¬: {
                    "bbox": [x1, y1, x2, y2],
                    "confidence": float,
                    "class_id": int
                }
        """
        # YOLO ì¶œë ¥ í˜•ì‹: (1, num_classes + 4, num_boxes) ë˜ëŠ” (1, num_boxes, num_classes + 4)
        output = outputs[0]
        
        # ì¶œë ¥ shape í™•ì¸ ë° ë³€í™˜
        if len(output.shape) == 3:
            # (1, 84, 8400) -> (8400, 84) í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            if output.shape[1] < output.shape[2]:
                output = output[0].T  # (8400, 84)
            else:
                output = output[0]    # (8400, 84)
        elif len(output.shape) == 2:
            pass  # ì´ë¯¸ (num_boxes, features) í˜•ì‹
        
        # bbox (cx, cy, w, h) + class scores ë¶„ë¦¬
        # YOLOv8 í˜•ì‹: [cx, cy, w, h, class0_score, class1_score, ...]
        boxes = output[:, :4]  # (N, 4)
        scores = output[:, 4:]  # (N, num_classes)
        
        # ê° ë°•ìŠ¤ì˜ ìµœëŒ€ í´ë˜ìŠ¤ ì ìˆ˜ ë° í´ë˜ìŠ¤ ID
        class_ids = np.argmax(scores, axis=1)
        confidences = np.max(scores, axis=1)
        
        # ì‹ ë¢°ë„ í•„í„°ë§
        mask = confidences >= conf_threshold
        boxes = boxes[mask]
        confidences = confidences[mask]
        class_ids = class_ids[mask]
        
        if len(boxes) == 0:
            return []
        
        # cx, cy, w, h -> x1, y1, x2, y2 ë³€í™˜
        boxes_xyxy = self._cxcywh_to_xyxy(boxes)
        
        # ì¢Œí‘œ ë³µì› (letterbox ì—­ë³€í™˜)
        scale, (pad_w, pad_h) = scale_factors
        orig_w, orig_h = original_size
        
        boxes_xyxy[:, [0, 2]] = (boxes_xyxy[:, [0, 2]] - pad_w) / scale
        boxes_xyxy[:, [1, 3]] = (boxes_xyxy[:, [1, 3]] - pad_h) / scale
        
        # ì´ë¯¸ì§€ ë²”ìœ„ë¡œ í´ë¦¬í•‘
        boxes_xyxy[:, [0, 2]] = np.clip(boxes_xyxy[:, [0, 2]], 0, orig_w)
        boxes_xyxy[:, [1, 3]] = np.clip(boxes_xyxy[:, [1, 3]], 0, orig_h)
        
        # NMS ì ìš©
        indices = self._nms(boxes_xyxy, confidences, iou_threshold)
        
        # ê²°ê³¼ ì •ë¦¬
        results = []
        for idx in indices:
            results.append({
                "bbox": boxes_xyxy[idx].tolist(),
                "confidence": float(confidences[idx]),
                "class_id": int(class_ids[idx])
            })
        
        return results
    
    def _cxcywh_to_xyxy(self, boxes: np.ndarray) -> np.ndarray:
        """
        ì¤‘ì‹¬ ì¢Œí‘œ í˜•ì‹ì„ ì½”ë„ˆ ì¢Œí‘œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        (cx, cy, w, h) -> (x1, y1, x2, y2)
        """
        boxes_xyxy = np.zeros_like(boxes)
        boxes_xyxy[:, 0] = boxes[:, 0] - boxes[:, 2] / 2  # x1
        boxes_xyxy[:, 1] = boxes[:, 1] - boxes[:, 3] / 2  # y1
        boxes_xyxy[:, 2] = boxes[:, 0] + boxes[:, 2] / 2  # x2
        boxes_xyxy[:, 3] = boxes[:, 1] + boxes[:, 3] / 2  # y2
        return boxes_xyxy
    
    def _nms(
        self, 
        boxes: np.ndarray, 
        scores: np.ndarray, 
        iou_threshold: float
    ) -> List[int]:
        """
        Non-Maximum Suppression (NMS) êµ¬í˜„
        
        Args:
            boxes: (N, 4) í˜•ì‹ì˜ ë°•ìŠ¤ ì¢Œí‘œ [x1, y1, x2, y2]
            scores: (N,) í˜•ì‹ì˜ ì‹ ë¢°ë„ ì ìˆ˜
            iou_threshold: IoU ì„ê³„ê°’
        
        Returns:
            List[int]: ìœ ì§€í•  ë°•ìŠ¤ì˜ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸
        """
        if len(boxes) == 0:
            return []
        
        # ì¢Œí‘œ ì¶”ì¶œ
        x1 = boxes[:, 0]
        y1 = boxes[:, 1]
        x2 = boxes[:, 2]
        y2 = boxes[:, 3]
        
        # ë©´ì  ê³„ì‚°
        areas = (x2 - x1) * (y2 - y1)
        
        # ì ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        order = scores.argsort()[::-1]
        
        keep = []
        while len(order) > 0:
            # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ë°•ìŠ¤ ì„ íƒ
            i = order[0]
            keep.append(i)
            
            if len(order) == 1:
                break
            
            # ë‚˜ë¨¸ì§€ ë°•ìŠ¤ë“¤ê³¼ì˜ IoU ê³„ì‚°
            xx1 = np.maximum(x1[i], x1[order[1:]])
            yy1 = np.maximum(y1[i], y1[order[1:]])
            xx2 = np.minimum(x2[i], x2[order[1:]])
            yy2 = np.minimum(y2[i], y2[order[1:]])
            
            inter_w = np.maximum(0, xx2 - xx1)
            inter_h = np.maximum(0, yy2 - yy1)
            inter_area = inter_w * inter_h
            
            union_area = areas[i] + areas[order[1:]] - inter_area
            iou = inter_area / (union_area + 1e-6)
            
            # IoUê°€ ì„ê³„ê°’ ì´í•˜ì¸ ë°•ìŠ¤ë§Œ ìœ ì§€
            inds = np.where(iou <= iou_threshold)[0]
            order = order[inds + 1]
        
        return keep
    
    def detect(
        self, 
        img_pil: Image.Image,
        conf_threshold: float = 0.25,
        iou_threshold: float = 0.45
    ) -> List[Dict]:
        """
        ê°ì²´ íƒì§€ ìˆ˜í–‰
        
        Args:
            img_pil: PIL Image ê°ì²´
            conf_threshold: ì‹ ë¢°ë„ ì„ê³„ê°’
            iou_threshold: NMS IoU ì„ê³„ê°’
        
        Returns:
            List[Dict]: íƒì§€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        # ì „ì²˜ë¦¬
        input_tensor, scale_factors, original_size = self.preprocess(img_pil)
        
        # ì¶”ë¡ 
        outputs = self.session.run(self.output_names, {self.input_name: input_tensor})
        
        # í›„ì²˜ë¦¬ (NMS í¬í•¨)
        results = self.postprocess(
            outputs, scale_factors, original_size,
            conf_threshold, iou_threshold
        )
        
        return results
    
    def detect_with_tracking_format(
        self,
        img_pil: Image.Image,
        conf_threshold: float = 0.25,
        iou_threshold: float = 0.45
    ) -> np.ndarray:
        """
        YOLO tracking í˜•ì‹ê³¼ í˜¸í™˜ë˜ëŠ” ì¶œë ¥ ë°˜í™˜
        
        Returns:
            np.ndarray: (N, 6) í˜•ì‹ [x1, y1, x2, y2, conf, class_id]
        """
        results = self.detect(img_pil, conf_threshold, iou_threshold)
        
        if not results:
            return np.array([])
        
        output = []
        for det in results:
            bbox = det["bbox"]
            output.append([
                bbox[0], bbox[1], bbox[2], bbox[3],
                det["confidence"], det["class_id"]
            ])
        
        return np.array(output)


# ==============================================================================
# ë“€ì–¼ ëª¨ë¸ íƒì§€ í•¨ìˆ˜ (ê¸°ì¡´ combat_system.pyì˜ í•¨ìˆ˜ ëŒ€ì²´)
# ==============================================================================

def detect_all_objects_dual_onnx(
    img_pil: Image.Image,
    detector_cannon: OnnxYoloDetector,
    detector_integrated: OnnxYoloDetector,
    combat_config,
    fusion_cfg,
    nms_iou_th: float = 0.5,
) -> Tuple[List[Dict], Dict]:
    """
    ONNX ë“€ì–¼ ëª¨ë¸ë¡œ ê°ì²´ë¥¼ íƒì§€í•˜ê³  NMS ì¤‘ì²© ì²˜ë¦¬
    
    Args:
        img_pil: PIL Image ê°ì²´ (íŒŒì¼ ê²½ë¡œ ëŒ€ì‹ )
        detector_cannon: Cannon ì „ìš© ONNX íƒì§€ê¸°
        detector_integrated: í†µí•© ê°ì²´ ONNX íƒì§€ê¸°
        combat_config: CombatSystemConfig ì¸ìŠ¤í„´ìŠ¤
        fusion_cfg: FusionConfig ì¸ìŠ¤í„´ìŠ¤
        nms_iou_th: NMS IoU ì„ê³„ê°’
    
    Returns:
        Tuple[List[Dict], Dict]: (íƒì§€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸, ë©”íƒ€ë°ì´í„°)
    """
    temp_detections = []
    
    model_configs = [
        {
            "detector": detector_cannon,
            "mapping": combat_config.map_cannon,
            "color": combat_config.color_cannon
        },
        {
            "detector": detector_integrated,
            "mapping": combat_config.map_integrated,
            "color": combat_config.color_integrated
        },
    ]
    
    for cfg in model_configs:
        # ONNX ì¶”ë¡ 
        detections = cfg["detector"].detect(
            img_pil,
            conf_threshold=fusion_cfg.min_det_conf,
            iou_threshold=0.45  # ë‚´ë¶€ NMS
        )
        
        for det in detections:
            class_id = det["class_id"]
            
            # ë§¤í•‘ í™•ì¸
            if class_id not in cfg["mapping"]:
                continue
            
            class_name = cfg["mapping"][class_id]
            bbox = det["bbox"]
            xmin, ymin, xmax, ymax = bbox
            
            # bbox í¬ê¸° í•„í„°
            if (xmax - xmin) < fusion_cfg.min_box_w or (ymax - ymin) < fusion_cfg.min_box_h:
                continue
            
            temp_detections.append({
                "bbox": bbox,
                "confidence": det["confidence"],
                "class_name": class_name,
                "color": cfg["color"],
            })
    
    # í¬ë¡œìŠ¤ ëª¨ë¸ NMS (confidence ë†’ì€ ìˆœìœ¼ë¡œ IoU overlap ì œê±°)
    temp_detections.sort(key=lambda x: x["confidence"], reverse=True)
    final_detections = []
    
    for cur in temp_detections:
        overlapped = False
        for kept in final_detections:
            if _iou(cur["bbox"], kept["bbox"]) > nms_iou_th:
                overlapped = True
                break
        if not overlapped:
            final_detections.append(cur)
    
    # ê²°ê³¼ ê°€ê³µ (UI ìŠ¤í‚¤ë§ˆ)
    filtered_results = []
    tank_count = 0
    red_count = 0
    last_cannon_bbox = None
    
    # bbox ì˜¤ë²„ë ˆì´ ì»¤ìŠ¤í„°ë§ˆì´ì§• ì„¤ì •
    bbox_styles = {
        "Tank": {
            "color": "#FF0000",
            "filled": True,
            "show_confidence": True,
        },
        "Red": {
            "color": "#FF4444",
            "filled": True,
            "show_confidence": True,
        },
        "Tree": {
            "color": "#AAAAAA",
            "filled": True,
            "show_confidence": False,
        },
        "Rock": {
            "color": "#AAAAAA",
            "filled": True,
            "show_confidence": False,
        },
        "default": {
            "color": "#FFFFFF",
            "filled": True,
            "show_confidence": False,
        }
    }
    
    for det in final_detections:
        name = det["class_name"]
        conf = det["confidence"]
        
        if name == "Tank":
            tank_count += 1
        elif name == "Red":
            red_count += 1
        elif name == "Cannon":
            last_cannon_bbox = det["bbox"]
            continue  # Cannonì€ ê·¸ë¦¬ì§€ ì•ŠìŒ
        
        style = bbox_styles.get(name, bbox_styles["default"])
        
        filtered_results.append({
            "className": name,
            "category": name.lower(),
            "bbox": det["bbox"],
            "confidence": conf,
            "color": style["color"],
            "filled": style["filled"],
            "updateBoxWhileMoving": False,
        })
    
    meta = {
        "tank_count": tank_count,
        "red_count": red_count,
        "cannon_bbox": last_cannon_bbox
    }
    
    return filtered_results, meta


def detect_tank_only_track_onnx(
    img_pil: Image.Image,
    detector: OnnxYoloDetector,
    class_map: dict,
    color_hex: str,
    min_det_conf: float,
    min_box_w: float,
    min_box_h: float,
    prev_detections: List[Dict] = None,
    iou_threshold: float = 0.3
) -> List[Dict]:
    """
    ONNX ê¸°ë°˜ Tank ì „ìš© íƒì§€ (ê°„ë‹¨í•œ IoU ê¸°ë°˜ íŠ¸ë˜í‚¹)
    
    Args:
        img_pil: PIL Image ê°ì²´
        detector: ONNX íƒì§€ê¸°
        class_map: í´ë˜ìŠ¤ ID -> ì´ë¦„ ë§¤í•‘
        color_hex: ë°•ìŠ¤ ìƒ‰ìƒ (hex)
        min_det_conf: ìµœì†Œ ì‹ ë¢°ë„
        min_box_w: ìµœì†Œ ë°•ìŠ¤ ë„ˆë¹„
        min_box_h: ìµœì†Œ ë°•ìŠ¤ ë†’ì´
        prev_detections: ì´ì „ í”„ë ˆì„ íƒì§€ ê²°ê³¼ (íŠ¸ë˜í‚¹ìš©)
        iou_threshold: íŠ¸ë˜í‚¹ IoU ì„ê³„ê°’
    
    Returns:
        List[Dict]: Tank íƒì§€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    # Tank class id ì¶”ì¶œ
    tank_cls_ids = [cid for cid, name in class_map.items() if name == "Tank"]
    
    # ONNX ì¶”ë¡ 
    all_detections = detector.detect(
        img_pil,
        conf_threshold=min_det_conf,
        iou_threshold=0.45
    )
    
    # Tank í´ë˜ìŠ¤ë§Œ í•„í„°ë§
    tank_detections = []
    for det in all_detections:
        if det["class_id"] in tank_cls_ids:
            bbox = det["bbox"]
            xmin, ymin, xmax, ymax = bbox
            
            if (xmax - xmin) < min_box_w or (ymax - ymin) < min_box_h:
                continue
            
            tank_detections.append({
                "bbox": bbox,
                "confidence": det["confidence"],
                "class_id": det["class_id"]
            })
    
    # ê°„ë‹¨í•œ IoU ê¸°ë°˜ íŠ¸ë˜í‚¹ (track_id í• ë‹¹)
    results = []
    next_track_id = 1
    
    # ì´ì „ íƒì§€ ê²°ê³¼ê°€ ìˆìœ¼ë©´ IoU ê¸°ë°˜ìœ¼ë¡œ track_id ì—°ê²°
    if prev_detections:
        used_prev_ids = set()
        
        for det in tank_detections:
            best_iou = 0
            best_prev_id = None
            
            for prev in prev_detections:
                if prev.get("track_id") in used_prev_ids:
                    continue
                
                iou = _iou(det["bbox"], prev["bbox"])
                if iou > best_iou and iou >= iou_threshold:
                    best_iou = iou
                    best_prev_id = prev.get("track_id")
            
            if best_prev_id is not None:
                track_id = best_prev_id
                used_prev_ids.add(track_id)
            else:
                # ìƒˆë¡œìš´ track_id í• ë‹¹
                track_id = max([p.get("track_id", 0) for p in prev_detections] + [0]) + 1
            
            det["track_id"] = track_id
    else:
        # ì´ì „ íƒì§€ ì—†ìœ¼ë©´ ìˆœì°¨ì ìœ¼ë¡œ ID í• ë‹¹
        for i, det in enumerate(tank_detections):
            det["track_id"] = i + 1
    
    # ê²°ê³¼ í¬ë§·íŒ…
    for det in tank_detections:
        track_id = det.get("track_id")
        conf = det["confidence"]
        
        display = f"Tank"
        if track_id is not None:
            display = f"[ID:{track_id}] Tank ({conf:.2f})"
        
        results.append({
            "className": display,
            "category": "tank",
            "bbox": det["bbox"],
            "confidence": conf,
            "color": color_hex,
            "filled": False,
            "updateBoxWhileMoving": False,
            "track_id": track_id,
        })
    
    return results


def _iou(box1: List[float], box2: List[float]) -> float:
    """
    ë‘ ë°•ìŠ¤ ê°„ì˜ IoU (Intersection over Union) ê³„ì‚°
    
    Args:
        box1: [x1, y1, x2, y2]
        box2: [x1, y1, x2, y2]
    
    Returns:
        float: IoU ê°’ (0.0 ~ 1.0)
    """
    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2])
    y2 = min(box1[3], box2[3])
    
    inter_w = max(0, x2 - x1)
    inter_h = max(0, y2 - y1)
    inter_area = inter_w * inter_h
    
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
    
    union_area = area1 + area2 - inter_area
    
    if union_area <= 0:
        return 0.0
    
    return inter_area / union_area


# ==============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ==============================================================================

def convert_pt_to_onnx(
    pt_path: str,
    onnx_path: str,
    input_size: int = 640,
    fp16: bool = True,
    simplify: bool = True
):
    """
    PyTorch YOLO ëª¨ë¸(.pt)ì„ ONNXë¡œ ë³€í™˜
    
    Args:
        pt_path: ì…ë ¥ .pt ëª¨ë¸ ê²½ë¡œ
        onnx_path: ì¶œë ¥ .onnx ëª¨ë¸ ê²½ë¡œ
        input_size: ì…ë ¥ í•´ìƒë„ (ì •ì‚¬ê°í˜•)
        fp16: FP16 ë³€í™˜ ì—¬ë¶€
        simplify: ONNX simplify ì ìš© ì—¬ë¶€
    
    Note:
        ultralytics íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.
        ë³€í™˜ ëª…ë ¹ì–´: yolo export model=best.pt format=onnx imgsz=640 half=True simplify=True
    """
    try:
        from ultralytics import YOLO
        
        model = YOLO(pt_path)
        model.export(
            format="onnx",
            imgsz=input_size,
            half=fp16,
            simplify=simplify,
            opset=12
        )
        
        print(f"[CONVERT] âœ… ONNX ë³€í™˜ ì™„ë£Œ: {onnx_path}")
        
    except ImportError:
        print("[CONVERT] âŒ ultralytics íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        print("  pip install ultralytics")
    except Exception as e:
        print(f"[CONVERT] âŒ ë³€í™˜ ì‹¤íŒ¨: {e}")


def benchmark_detector(detector: OnnxYoloDetector, img_pil: Image.Image, iterations: int = 100):
    """
    íƒì§€ê¸° ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
    
    Args:
        detector: OnnxYoloDetector ì¸ìŠ¤í„´ìŠ¤
        img_pil: í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€
        iterations: ë°˜ë³µ íšŸìˆ˜
    """
    # ì›Œë°ì—…
    for _ in range(10):
        detector.detect(img_pil)
    
    # ë²¤ì¹˜ë§ˆí¬
    start = time.time()
    for _ in range(iterations):
        detector.detect(img_pil)
    elapsed = time.time() - start
    
    avg_ms = (elapsed / iterations) * 1000
    fps = iterations / elapsed
    
    print(f"[BENCHMARK] í‰ê·  ì¶”ë¡  ì‹œê°„: {avg_ms:.2f}ms")
    print(f"[BENCHMARK] FPS: {fps:.1f}")


# ==============================================================================
# í…ŒìŠ¤íŠ¸ ì½”ë“œ
# ==============================================================================

if __name__ == "__main__":
    print("=" * 60)
    print("ONNX YOLO Detector í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
    test_img = Image.new("RGB", (1280, 720), color=(100, 100, 100))
    
    print("\n[í…ŒìŠ¤íŠ¸] PIL Image ì „ì²˜ë¦¬")
    if ONNX_AVAILABLE:
        # ì‹¤ì œ ëª¨ë¸ì´ ì—†ìœ¼ë¯€ë¡œ ì „ì²˜ë¦¬ë§Œ í…ŒìŠ¤íŠ¸
        print("  - onnxruntime ì‚¬ìš© ê°€ëŠ¥")
        print("  - ì‹¤ì œ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ì„œëŠ” .onnx ëª¨ë¸ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # ë³€í™˜ ëª…ë ¹ì–´ ì•ˆë‚´
        print("\n[ëª¨ë¸ ë³€í™˜ ë°©ë²•]")
        print("  yolo export model=models/best.pt format=onnx imgsz=640 half=True simplify=True")
    else:
        print("  - onnxruntimeì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("  - pip install onnxruntime-gpu  (GPU ì‚¬ìš© ì‹œ)")
        print("  - pip install onnxruntime      (CPU ì „ìš©)")
